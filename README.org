#+OPTIONS: ^:nil
This repository contains the Rocq mechanization of the results from the paper
"Algorithmic Conversion with Surjective Pairing: A Syntactic and
Untyped Approach".

While the documentation is written in =org= mode, it is recommended
that you use the generated =README.html= file so you can access the
hyperlinks into the generated coqdoc files to navigate the development
in your web browser by launching a local web server using [[https://docs.python.org/3/library/http.server.html][python]] or
[[https://github.com/emikulic/darkhttpd][darkhttpd]]. Note that if you instead load the file directly with your
web server, the toggle proof functionality of coqdocjs will not work
because of CORS restrictions of javascript modules!

#+begin_src sh
# starting a local server with python listening to port 8080
python -m http.server --bind 127.0.0.1 8080 --directory .
# alternatively, starting a local server with darkhttpd listening to port 8080
darkhttpd . --addr 127.0.0.1 --port 8080
#+end_src
You can then access the document from your web browser with the url =http://127.0.0.1:8080=.

As mentioned in the paper, while the natural numbers are omitted from
the text, they can be found in the mechanization and the [[./specification.pdf][specification]]
pdf file.

** Quick start

*** Installing dependencies
You can skip this section if you are compiling the proof scripts from
the configured VM.

Inside a fresh =opam= switch, run the following commands to install
the required dependencies.
#+begin_src sh
opam update
opam repo add rocq-released https://rocq-prover.org/opam/released
opam install -y coq-hammer-tactics coq-stdpp coq-autosubst-ocaml
eval $(opam env)
#+end_src

The termination proof can be brittle because we expect the =inversion=
to produce the subproofs of the domain relation that make the termination checker happy.

Here are the dependencies and version numbers that have been tested.
- rocq 9.0.1
- coq-stdpp 1.12.0
- coq-hammer-tactics 1.3.2+9.0
- coq-autosubst-ocaml 1.1

Note that if you don't plan to modify and regenerate the =syntax.v=
file from =syntax.sig= using =autosubst=, you can choose not to install =coq-autosubst-ocaml=.
However, you need to be careful not to accidentally run =make deepclean=,
which will delete the auto-generated syntax files. Instead, run =make
clean= if you want to keep the auto-generated files.

*** Validating the proofs
After the dependencies are installed, run the following command to
validate the proof development.  The =-j2= flag allows =make= to
validate up to 2 files in parallel. According to our testing, going
beyond =-j2= does not reduce the compilation time.
#+begin_src sh
make -j2
#+end_src

It is expected that the compilation process will generate a lot of
warnings about notations and the ssreflect library. The compilation is
successful as long as the command terminates with the following
output.
#+begin_src sh
# ... lots of warnings ...
make[1]: Leaving directory '****'
#+end_src


On a Linux laptop with an Intel 12700k, the compilation takes 67
seconds. If you are running the command inside the attached VM and
your host device has an ARM CPU (e.g. Mac M-series), then it'll take
around 10x longer since emulating x86 instructions can be quite slow.

** Definitions

*** Grammar (Fig. 1)
- Terms: [[file:html/DecSyn.Autosubst2.syntax.html#Core.PTm][PTm]]
- Typing context: defined directly as =list PTm=

The grammar specification in higher-order abstract syntax (HOAS) can
be found in [[file:./syntax.sig][syntax.sig]]. We use the autosubst-ocaml tool to turn the
syntax file into the Rocq file [[./theories/Autosubst2/syntax.v][syntax.v]], which contains not only the
de Bruijn grammar but also definitions of renaming and
substitution functions and their associated lemmas.

*** Typing specification (Fig. 2, 3)
- Typing: [[./html/DecSyn.typing.html#Wt][Wt]] ($\Gamma \vdash a \in A$)
- Equality: [[./html/DecSyn.typing.html#Eq][Eq]] ($\Gamma \vdash a \equiv b \in A$)
- Subtyping: [[./html/DecSyn.typing.html#LEq][LEq]] ($\Gamma \vdash A \lesssim B$)
- Context well-formedness: [[./html/DecSyn.typing.html#Wff][Wff]] ($\vdash \Gamma$)



*** Untyped relations and naming schemes
Due to the many reduction relations used in our proof, we organize
each untyped reduction, equality, and subtyping relation inside its
own module, where the relation itself is simply named =R=. Thus, to
avoid ambiguity, those modules are never meant to be imported and the
relation should always be referred to in its qualified form.  For
example, the $\beta$-reduction relation is defined as the inductive
type [[./html/DecSyn.fp_red.html#RRed.R][R]] in the module [[./html/DecSyn.fp_red.html#RRed][RRed]]. Outside the module, the $\beta$-reduction
relation is referred to by its fully qualified name =RRed.R=.

Given a module containing a reduction relation named =Red=,
the module =Reds= contains the properties about its reflexive and
transitive closure. Instead of defining the transitive and reflexive
closure of =Red.R= as =RReds.R=, we directly refer to it as =rtc
RRed.R=, where =rtc= is a relation operator that outputs the reflexive
and transitive closure of its input.

Some relations are standard and therefore not included in the text for
concision, but we include them here for completeness.

**** Normal form predicates (Fig. 5)
- normal forms (nf): [[./html/DecSyn.fp_red.html#nf][nf]]
- neutral forms (nf): [[./html/DecSyn.fp_red.html#ne][ne]]
- canonical forms (canf): [[./html/DecSyn.common.html#ishf][ishf]]
- weak-head neutral forms (whne): [[./html/DecSyn.common.html#ishne][ishne]]
- weak-head normal forms (whnf): inlined as the union of =ishf= and
  =ishne=

Note that we sometimes use [[./html/DecSyn.common.html#HRed.nf][HRed.nf]] in place of the above definition of
whnf, where the former means the term would no longer reduce with
weak-head reduction. These two definitions coincide for precisely the
set of terms that are non-stuck.

Also, instead of defining [[./html/DecSyn.fp_red.html#nf][nf]] and [[./html/DecSyn.fp_red.html#ne][ne]] as inductive predicates, we define
them as mutually recursive fixpoints. For the definition to be
accepted by the termination checker, the injection from ne to nf is
proven a posteriori as the lemma [[./html/DecSyn.fp_red.html#ne_nf][ne_nf]].

**** Reductions
- $\beta$-reduction ($\leadsto_\beta$): [[./html/DecSyn.fp_red.html#RRed][RRed]]
- $\eta$-reduction ($\leadsto_\eta$): [[./html/DecSyn.fp_red.html#ERed][ERed]]
- parallel $\beta$-reduction ($\Rightarrow_\beta$): [[./html/DecSyn.fp_red.html#RPar][RPar]]
- parallel $\eta$-reduction ($\Rightarrow_\eta$): [[./html/DecSyn.fp_red.html#EPar][EPar]]
- $\beta\eta$-reduction ($\leadsto_{\beta\eta}$): [[./html/DecSyn.fp_red.html#RERed][RERed]]
- leftmost-outermost $\beta$-reduction ($\leadsto_{\beta}$): [[./html/DecSyn.fp_red.html#LoRed][LoRed]]
- weak-head $\beta$-reduction: [[./html/DecSyn.common.html#HRed][HRed]]
- restrictive parallel $\eta$-reductions ($\Rightarrow_r$, $\Rightarrow_{\bar{r}}$): [[./html/DecSyn.fp_red.html#NeEPar][NeEPar]]
**** Strong normalization (Sec. 3.2)
- Strong normal forms: [[./html/DecSyn.fp_red.html#SN][SN]]
- Strong neutral forms: [[./html/DecSyn.fp_red.html#SNe][SNe]]
- Strong weak head reduction: [[./html/DecSyn.fp_red.html#TRedSN][TRedSN]]
**** Joinability and Subtyping
- Joinability (w.r.t $\beta\eta$-reduction, Def. 3.1): [[./html/DecSyn.fp_red.html#DJoin][DJoin]]
- Joinability (w.r.t $\eta$-reduction): [[./html/DecSyn.fp_red.html#EJoin][EJoin]]

- One-step subtyping (Page 12): [[./html/DecSyn.fp_red.html#Sub1][Sub1]]
- Untyped subtyping (Def. 3.2): [[./html/DecSyn.fp_red.html#Sub][Sub]]
- Untyped subtyping (w.r.t $\eta$-reduction): [[./html/DecSyn.fp_red.html#ESub][ESub]]

Note that [[./html/DecSyn.fp_red.html#ESub][ESub]] holds when two terms can be related by one-step
subtyping after $\eta$-reduction. It is not mentioned in the paper but
is convenient to have around in the mechanization for automation purposes.
**** Coquand's algorithm (Sec. 4.1)
Coquand's algorithm is one of the exceptions of the above naming
scheme, and the actual formal definition is slightly different from
the text presentation. Notably, the algorithmic equality for head
normal forms is split into two relations, one that handles the case
where both terms are neutral, and one that handles the cases where at
least one term is not neutral.


- Algorithmic equality ($a \leftrightarrow b$ in the text): [[./html/DecSyn.algorithmic.html#CoqEq_R][CoqEq_R]] ($a
  \Leftrightarrow b$ in the mechanization)
- Algorithmic equality for head normal forms ($f_0 \sim f_1$ in the
  text):
  + When both inputs are neutral: [[./html/DecSyn.algorithmic.html#CoqEq_Neu][CoqEq_Neu]] ($a \sim b$ in the mechanization)
  + Otherwise: [[./html/DecSyn.algorithmic.html#CoqEq][CoqEq]] ($a \leftrightarrow b$ in the mechanization)
- Termination metric: [[./html/DecSyn.algorithmic.html#sn_term_metric][sn_term_metric]]

The relations are all formulated on arbitrary terms.  The neutral and
normal form restrictions in $f_0 \sim f_1$ are proven a posteriori as
lemmas in the mechanization (e.g. [[./html/DecSyn.executable_correct.html#coqeq_no_hred][coqeq_no_hred]]).


Subtyping works similarly, though there is no need to split the
relation as the neutral case is handled by equalities.

- Algorithmic subtyping ($A \ll B$): [[./html/DecSyn.algorithmic.html#CoqLEq_R][CoqLEq_R]]
- Algorithmic subtyping for head normal forms ($f_0 \lesssim f_1$): [[./html/DecSyn.algorithmic.html#CoqLEq][CoqLEq]]

*** The untyped logical predicate (Sec 3.7)
As mentioned in the text, the definition of the logical predicate
cannot be written in Rocq directly as it consists of an inductive
definition nested in a fixpoint definition over universe levels.

The technique we adopt to encode the logical relation is described in
detail in the [[https://www.seas.upenn.edu/~sweirich/papers/liu-mltt-consistency.pdf][write-up]] by Liu and Weirich. To make the code more
readable, we specify a module type [[./html/DecSyn.logrel.html#LogRel][LogRel]] that includes the
introduction and induction principles that fully characterizes the
logical predicate. The module [[./html/DecSyn.logrel.html#LogRelImpl][LogRelImpl]] shows how the logical
predicate is actually defined through the inductive definition
[[./html/DecSyn.logrel.html#LogRelImpl.InterpExt][InterpExt]] and the fixpoint [[./html/DecSyn.logrel.html#LogRel.InterpUniv][InterpUniv]], the latter of which the logical
predicate satisfying the abstract properties we actually need.

By encapsulating the Rocq-specific workarounds behind the module
signature, the properties about the logical predicate (found in
[[./html/DecSyn.logrel.html#LogRelFactsImpl][LogRelFactsImpl]]) can be implemented purely in terms of the clean
interface specified in [[./html/DecSyn.logrel.html#LogRel][LogRel]].

- logical predicate ($\llbracket A \rrbracket \searrow S$):
  InterpUniv ([[./html/DecSyn.logrel.html#LogRel.InterpUniv][signature]], [[./html/DecSyn.logrel.html#LogRelImpl.InterpUniv][implementation]])
  + induction principle ([[./html/DecSyn.logrel.html#LogRel.InterpUniv_ind][signature]], [[./html/DecSyn.logrel.html#LogRelImpl.InterpUniv_ind][implementation]])
  + introduction rules (omitted, defined in the same module)

To avoid introducing propositional and functional extensionality
axioms, we add rule [[./html/DecSyn.logrel.html#LogRel.InterpUniv_Conv][InterpUniv_Conv]] to our mechanization
to ensure that the logical predicate operates on predicates that are
extensionally equivalent (denoted by $\doteq$ in the
mechanization). These artifacts introduced by avoiding the axioms are
noted in the development and can be safely ignored.

*** Executable conversion algorithm (Sec. 4)
The relational definition of algorithmic conversion is not immediately
executable. The decidability result (Theorem 4.1) is justified by
defining a total function that returns true precisely when two of its
input are convertible.

Here, we give links to the definition of the algorithm and the
Bove-Capretta domains to handle termination checking.

- Executable algorithmic
  - subtyping: [[./html/DecSyn.executable.html#check_sub_r][check_sub_r]]
  - equality: [[./html/DecSyn.executable.html#check_equal_r][check_equal_r]]
- Bove-Capretta domains for
  - subtyping: [[./html/DecSyn.common.html#salgo_dom_r][salgo_dom_r]]
  - equality: [[./html/DecSyn.common.html#algo_dom_r][algo_dom_r]]

The completeness and soundness of the computable functions with
respect to their relational counterparts are not explicitly included
in the paper, but they are linked in the mechanization by the
following lemmas.

- subtyping: [[./html/DecSyn.executable_correct.html#check_sub_sound][check_sub_sound]], [[./html/DecSyn.executable_correct.html#check_sub_complete][check_sub_complete]]
- equality: [[./html/DecSyn.executable_correct.html#check_eq_sound][check_eq_sound]], [[./html/DecSyn.executable_correct.html#check_eq_complete][check_eq_complete]]

The termination of algorithmic conversion is implied by the
above completeness and soundness results.

** Properties proven in the paper


*** Section 2
- Lemma 2.1 (context regularity) :: [[./html/DecSyn.structural.html#wff_mutual][wff_mutual]]
- Lemma 2.2 (inversion) :: [[./html/DecSyn.structural.html#Bind_Inv][Bind_Inv]], [[./html/DecSyn.structural.html#Var_Inv][Var_Inv]], [[./html/DecSyn.admissible.html#App_Inv][App_Inv]], [[./html/DecSyn.admissible.html#Abs_Inv][Abs_Inv]],
  [[./html/DecSyn.admissible.html#Proj1_Inv][Proj1_Inv]], [[./html/DecSyn.admissible.html#Proj2_Inv][Proj2_Inv]], [[./html/DecSyn.admissible.html#Pair_Inv][Pair_Inv]]
- Lemma 2.3 (subject reduction) :: [[./html/DecSyn.preservation.html#subject_reduction][subject_reduction]]
- Lemma 2.4 (type correctness) :: [[./html/DecSyn.structural.html#regularity][regularity]]
*** Section 3
- Lemma 3.1 :: [[./html/DecSyn.fp_red.html#RRed.nf_imp][RRed.nf_imp]]
- Lemma 3.2 :: [[./html/DecSyn.fp_red.html#ERed.nf_preservation][ERed.nf_preservation]]
- Lemma 3.3 :: [[./html/DecSyn.fp_red.html#LoReds.FromSN_mutual][LoReds.FromSN_mutual]]
- Lemma 3.4 (no stuck terms) :: [[./html/DecSyn.fp_red.html#SN_NoForbid.PApp_imp][SN_NoForbid.PApp_imp]],
  [[./html/DecSyn.fp_red.html#SN_NoForbid.PProj_imp][SN_NoForbid.PProj_imp]], [[./html/DecSyn.fp_red.html#SN_NoForbid.PInd_imp][SN_NoForbid.PInd_imp]] (the $P$ property is
  defined as $SN$)
- Lemma 3.5 (SN renaming) :: [[./html/DecSyn.fp_red.html#sn_renaming][sn_renaming]]
- Lemma 3.6 (SN antisubstitution) :: [[./html/DecSyn.fp_red.html#sn_unmorphing][sn_unmorphing]]
- Lemma 3.7 (SN inversion)  :: [[./html/DecSyn.fp_red.html#P_AppInv][P_AppInv]], [[./html/DecSyn.fp_red.html#P_PairInv][P_PairInv]], [[./html/DecSyn.fp_red.html#P_ProjInv][P_ProjInv]],
  [[./html/DecSyn.fp_red.html#P_BindInv][P_BindInv]], [[./html/DecSyn.fp_red.html#P_SucInv][P_SucInv]], [[./html/DecSyn.fp_red.html#P_AbsInv][P_AbsInv]], [[./html/DecSyn.fp_red.html#P_IndInv][P_IndInv]]
- Lemma 3.8 (sn preservation) :: split into two separate lemmas
  + preservation for parallel $\eta$-reduction :: [[./html/DecSyn.fp_red.html#epar_sn_preservation][epar_sn_preservation]]
  + preservation for parallel $\beta$-reduction :: [[./html/DecSyn.fp_red.html#red_sn_preservation][red_sn_preservation]]
- Lemma 3.9 (restrictive-$\eta$ and normal form) :: [[./html/DecSyn.fp_red.html#NeEPar.R_elim_nf][NeEPar.R_elim_nf]]
- Lemma 3.10 ($\eta$-decomposition) :: [[./html/DecSyn.fp_red.html#94f0c3df8362a7b158dcddfe72d0bd43][UniqueNF.η_split]]. Note: we
  parameterize the proof over the $P$ predicate as mentioned in
  Sec. 5.3. The $P$ predicate is instantiated to $SN$ in [[./html/DecSyn.fp_red.html#SN_NoForbid][SN_NoForbid]]
- Lemma 3.11 ($\eta$-postponement) :: [[./html/DecSyn.fp_red.html#UniqueNF.358dc2826f57a708afef6c267d5b924f][UniqueNF.η_postponement]]
- Corollary 3.1 (strengthened $\eta$-postponement) :: [[./html/DecSyn.fp_red.html#4033bdffc216f18a15ba122e3b94bf46][UniqueNF.η_postponement_strengthened]]
- Corollary 3.2 ($\eta$-postponement for normal forms) :: [[./html/DecSyn.fp_red.html#rered_standardization'][rered_standardization']]
- Lemma 3.12 (confluence for $\beta$) :: [[./html/DecSyn.fp_red.html#red_confluence][red_confluence]]
- Lemma 3.13 (confluence for $\eta$) :: [[./html/DecSyn.fp_red.html#ered_confluence][ered_confluence]]
- Theorem 3.1 (confluence for $\beta\eta$ :: [[./html/DecSyn.fp_red.html#rered_confluence][rered_confluence]]
- Lemma 3.14 (transitivity of joinability) :: [[./html/DecSyn.fp_red.html#DJoin.transitive][DJoin.transitive]]
- Lemma 3.15 (injectivity of joinability) :: [[./html/DecSyn.fp_red.html#DJoin.hne_app_inj][DJoin.hne_app_inj]], [[./html/DecSyn.fp_red.html#DJoin.hne_proj_inj][DJoin.hne_proj_inj]]
- Lemma 3.16 (transitivity of one-step subtyping) :: [[./html/DecSyn.fp_red.html#Sub1.transitive][Sub1.transitive]]
- Lemma 3.17 (commutativity of one-step subtyping) :: [[./html/DecSyn.fp_red.html#Sub1.commutativity0][Sub1.commutativity0]]
- Lemma 3.18 (one-step subtyping preserves sn) :: [[./html/DecSyn.fp_red.html#Sub1.sn_preservation][Sub1.sn_preservation]]
- Corollary 3.3 (transitivity of untyped subtyping) :: [[./html/DecSyn.fp_red.html#Sub.transitive][Sub.transitive]]
- Lemma 3.19 (noconfusion for untyped subtyping) :: The Sub.*_noconf
  lemmas starting with [[./html/DecSyn.fp_red.html#Sub.sne_nat_noconf][Sub.sne_nat_noconf]]
- Lemma 3.20 (untyped injectivity of type constructors) ::  [[./html/DecSyn.fp_red.html#Sub.bind_inj][Sub.bind_inj]], [[./html/DecSyn.fp_red.html#Sub.univ_inj][Sub.univ_inj]]
- Lemma 3.21 (adequacy) :: [[./html/DecSyn.logrel.html#LogRelFactsImpl.adequacy][LogRelFactsImpl.adequacy]]
- Lemma 3.22 (backward closure) :: [[./html/DecSyn.logrel.html#LogRelFactsImpl.back_clos][LogRelFactsImpl.back_clos]]
- Lemma 3.23 (logical predicate cases) :: [[./html/DecSyn.logrel.html#LogRelFactsImpl.case][LogRelFactsImpl.case]]
- Lemma 3.24 (logical predicate is preserved by subtyping) :: [[./html/DecSyn.logrel.html#LogRelFactsImpl.sub][LogRelFactsImpl.sub]]
- Corollary 3.4 (logical predicate is functional)  :: [[./html/DecSyn.logrel.html#LogRelFactsImpl.functional][LogRelFactsImpl.functional]]
- Lemma 3.25 (logical predicate is cumulative) :: [[./html/DecSyn.logrel.html#LogRelFactsImpl.cumulative][LogRelFactsImpl.cumulative]]
- Lemma 3.26 (semantic weakening) :: [[./html/DecSyn.logrel.html#weakening_Sem][weakening_Sem]]
- Lemma 3.27 (semantic substitution) :: [[./html/DecSyn.logrel.html#morphing_SemWt][morphing_SemWt]]
- Lemma 3.28 (structural rules for semantic well-formedness) :: [[./html/DecSyn.logrel.html#SemWff_lookup][SemWff_lookup]]
- Theorem 3.2 (fundamental theorem) :: [[./html/DecSyn.soundness.html#fundamental_theorem][fundamental_theorem]]
- Corollary 3.5 (completeness of reduce-and-compare) :: Inlined into
  proof scripts
- Corollary 3.6 (completeness of reduce-and-compare) :: [[./html/DecSyn.soundness.v.html#synsub_to_usub][synsub_to_usub]]
*** Section 4
- Lemma 4.1 ($\Pi$-subtyping) :: [[./html/DecSyn.algorithmic.html#Sub_Bind_InvL][Sub_Bind_InvL]], [[./html/DecSyn.algorithmic.html#Sub_Bind_InvR][Sub_Bind_InvR]]
- Lemma 4.2 (univ-subtyping) :: [[./html/DecSyn.algorithmic.html#Sub_Univ_InvR][Sub_Univ_InvR]]
- Lemma 4.3 (soundness for algorithmic equality) :: [[./html/DecSyn.algorithmic.html#coqeq_sound_mutual][coqeq_sound_mutual]]
- Lemma 4.4 (soundness for algorithmic subtyping) :: [[./html/DecSyn.algorithmic.html#coqleq_sound_mutual][coqleq_sound_mutual]]
- Lemma 4.5 (metric implies domain) :: [[./html/DecSyn.algorithmic.html#sn_term_metric][sn_term_metric]]
- Lemma 4.6 (termination of Coquand's algorithm) :: [[./html/DecSyn.executable.html#check_sub_r][check_sub_r]]
  (termination is implicit in our mechanization in the sense that we can construct
  the Bove-Capretta domain from the typing judgment, which we can then
  feed to the [[./html/DecSyn.executable.html#check_sub_r][check_sub_r]] function)
- Lemma 4.7 (completeness of Coquand's algorithm) :: [[./html/DecSyn.algorithmic.html#coqeq_complete'][coqeq_complete']]
- Lemma 4.8 (completeness of Coquand's algorithmic subtyping) :: [[./html/DecSyn.algorithmic.html#coqleq_complete'][coqleq_complete']]
- Lemma 4.9 (completeness of Coquand's algorithmic subtyping) :: [[./html/DecSyn.algorithmic.html#coqleq_complete_unty][coqleq_complete_unty]], [[./html/DecSyn.algorithmic.html#coqleq_complete][coqleq_complete]], [[./html/DecSyn.algorithmic.html#coqleq_sound][coqleq_sound]]
- Theorem 4.1 (type conversion is decidable) :: In Rocq, we have to go
  an extra mile by defining the computable function [[./html/DecSyn.conv_dec.html#check_sub_r_wt][check_sub_r_wt]]
  (a wrapper around [[./html/DecSyn.executable.html#check_sub_r][check_sub_r]]) and then prove that it agrees with
  the inductive subtyping relation in [[./html/DecSyn.conv_dec.html#Conv_dec][Conv_dec]]
*** Section 5
- Proposition 5.1 :: [[./html/DecSyn.cosn.html#Safe_NoForbid][Safe_NoForbid]]

** Validating axiom usage
We claim that our development is axiom-free. To validate that claim,
one can use the =Print Assumptions= command on the theorems and
confirm that no axioms are displayed.

An alternative method is to run =coqchk=, which can be invoked on all
=.vo= files by running
=make validate=. However, =coqchk= doesn't work that well with module
types and will report axioms that we didn't actually use in the
development.

#+begin_src sh
,* Theory: Set is predicative

,* Theory: Rewrite rules are not allowed

,* Axioms:
    DecSyn.logrel.LRFacts.functional
    DecSyn.logrel.LRFacts.Bind_inv_nopf
    DecSyn.logrel.LRFacts.back_clos
    DecSyn.logrel.LRFacts.Bind_nopf
    DecSyn.logrel.LRFacts.adequacy
    DecSyn.logrel.LRFacts.back_closs
    Coq.Logic.FunctionalExtensionality.functional_extensionality_dep
    Coq.Reals.ClassicalDedekindReals.sig_not_dec
    DecSyn.logrel.LRFacts.join
    DecSyn.logrel.LRFacts.case
    DecSyn.logrel.LRFacts.sub
    Coq.Reals.ClassicalDedekindReals.sig_forall_dec
    DecSyn.logrel.LRFacts.cumulative
    DecSyn.logrel.LRFacts.Univ_inv
    DecSyn.logrel.LRFacts.SNe_inv
    DecSyn.logrel.LRFacts.Bind_inv
    Coq.Logic.Eqdep.Eq_rect_eq.eq_rect_eq
    DecSyn.fp_red.NoForbid_FactSN.P_RReds
    DecSyn.fp_red.NoForbid_FactSN.P_EPars
    DecSyn.logrel.LRFacts.Nat_inv

,* Constants/Inductives relying on type-in-type: <none>

,* Constants/Inductives relying on unsafe (co)fixpoints: <none>

,* Inductives whose positivity is assumed: <none>

make[1]: Leaving directory '****'
#+end_src

Again, all the axiom reported are false positives and you should
always trust =Print Assumptions= when it comes to axiom usage. Still,
the output provides the useful information that our development does
not rely on any of the dangerous or inconsistent features that would
make our theorems trivially true.
