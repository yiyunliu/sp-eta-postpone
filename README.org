This repository contains the Rocq mechanization of the results from the paper
"Algorithmic Conversion with Surjective Pairing: A Syntactic and
Untyped Approach".

While the documentation is written in =org= mode, it is recommended
that you use the generated =README.html= file so you can access the
hyperlinks into the generated coqdoc files to navigate the development
in your web browser. Firefox seems to struggle to render some of the
larger coqdocjs files. If you experience any performance issues,
consider opening the html file with Chromium/Chrome.


** Quick start
Inside a fresh =opam= switch, run the following commands to install
the required dependencies.
#+begin_src sh
opam update
opam install -y coq-hammer-tactics coq-equations coq-stdpp coq-autosubst-ocaml
eval $(opam env)
#+end_src

After the dependencies are installed, run the following command to
validate the proof development.  The =-j2= flag allows =make= to
validate up to 2 files in parallel. According to our testing, going
beyond =-j2= does not reduce the compilation time significantly.
#+begin_src sh
make -j2
#+end_src

The termination proof can be brittle because we expect the =inversion=
to produce the subproofs of the domain relation that make the termination checker happy.

Here are the versions of the Rocq packages that are known to
work.
- coq 8.20.1
- coq-stdpp 1.11.0
- coq-hammer-tactics 1.3.2
- coq-autosubst-ocaml 1.1

Note that if you don't plan to modify and regenerate the =syntax.v=
file from =syntax.sig= using =autosubst=, you can choose not to install =coq-autosubst-ocaml=.
However, you need to be careful not to accidentally run =make deepclean=,
which will delete the auto-generated syntax files. Instead, run =make
clean= if you want to keep the auto-generated files.

** Definitions

*** Grammar (Fig. 1)
- Terms: [[file:html/DecSyn.Autosubst2.syntax.html#Core.PTm][PTm]]
- Typing context: defined directly as =list PTm=

The grammar specification in higher-order abstract syntax (HOAS) can
be found in [[file:./syntax.sig][syntax.sig]]. We use the autosubst-ocaml tool to turn the
syntax file into the Rocq file [[./theories/Autosubst2/syntax.v][syntax.v]], which contains not only the
de Bruijn grammar but also definitions of renaming and
substitution functions and their associated lemmas.

*** Typing specification (Fig. 2, 3)
- Typing: [[./html/DecSyn.typing.html#Wt][Wt]] ($\Gamma \vdash a \in A$)
- Equality: [[./html/DecSyn.typing.html#Eq][Eq]] ($\Gamma \vdash a \equiv b \in A$)
- Subtyping: [[./html/DecSyn.typing.html#LEq][LEq]] ($\Gamma \vdash A \lesssim B$)
- Context well-formedness: [[./html/DecSyn.typing.html#Wff][Wff]] ($\vdash \Gamma$)



*** Untyped relations and naming schemes
Due to the many reduction relations used in our proof, we organize
each untyped reduction, equality, and subtyping relation inside its
own module, where the relation itself is simply named =R=. Thus, to
avoid ambiguity, those modules are never meant to be imported and the
relation should always be referred to in its qualified form.  For
example, the $\beta$-reduction relation is defined as the inductive
type [[./html/DecSyn.fp_red.html#RRed.R][R]] in the module [[./html/DecSyn.fp_red.html#RRed][RRed]]. Outside the module, the $\beta$-reduction
relation is referred to by its fully qualified name =RRed.R=.

Given a module containing a reduction relation named =Red=,
the module =Reds= contains the properties about its reflexive and
transitive closure. Instead of defining the transitive and reflexive
closure of =Red.R= as =RReds.R=, we directly refer to it as =rtc
RRed.R=, where =rtc= is a relation operator that outputs the reflexive
and transitive closure of its input.

Some relations are standard and therefore not included in the text for
concision, but we include them here for completeness.

**** Normal form predicates (Fig. 5)
- normal forms (nf): [[./html/DecSyn.fp_red.html#nf][nf]]
- neutral forms (nf): [[./html/DecSyn.fp_red.html#ne][ne]]
- canonical forms (canf): [[./html/DecSyn.common.html#ishf][ishf]]
- weak-head neutral forms (whne): [[./html/DecSyn.common.html#ishne][ishne]]
- weak-head normal forms (whnf): inlined as the union of =ishf= and
  =ishne=

Note that we sometimes use [[./html/DecSyn.common.html#HRed.nf][HRed.nf]] in place of the above definition of
whnf, where the former means the term would no longer reduce with
weak-head reduction. These two definitions coincide for precisely the
set of terms that are non-stuck.

Also, instead of defining [[./html/DecSyn.fp_red.html#nf][nf]] and [[./html/DecSyn.fp_red.html#ne][ne]] as inductive predicates, we define
them as mutually recursive fixpoints. For the definition to be
accepted by the termination checker, the injection from ne to nf is
proven a posteriori as the lemma [[./html/DecSyn.fp_red.html#ne_nf][ne_nf]].

**** Reductions
- $\beta$-reduction: [[./html/DecSyn.fp_red.html#RRed][RRed]]
- $\eta$-reduction: [[./html/DecSyn.fp_red.html#ERed][ERed]]
- parallel $\beta$-reduction: [[./html/DecSyn.fp_red.html#RPar][RPar]]
- parallel $\eta$-reduction: [[./html/DecSyn.fp_red.html#EPar][EPar]]
- parallel $\beta\eta$-reduction: [[./html/DecSyn.fp_red.html#RERed][RERed]]
- leftmost-outermost $\beta$-reduction: [[./html/DecSyn.fp_red.html#LoRed][LoRed]]
- weak-head $\beta$-reduction: [[./html/DecSyn.common.html#HRed][HRed]]
- restrictive parallel $\eta$-reductions (Fig. 6): [[./html/DecSyn.fp_red.html#NeEPar][NeEPar]]
**** Strong normalization (Sec. 3.2)
- Strong normal forms: [[./html/DecSyn.fp_red.html#SN][SN]]
- Strong neutral forms: [[./html/DecSyn.fp_red.html#SNe][SNe]]
- Strong weak head reduction: [[./html/DecSyn.fp_red.html#TRedSN][TRedSN]]
**** Joinability and Subtyping
- Joinability (w.r.t $\beta\eta$-reduction, Def. 3.1): [[./html/DecSyn.fp_red.html#DJoin][DJoin]]
- Joinability (w.r.t $\eta$-reduction): [[./html/DecSyn.fp_red.html#EJoin][EJoin]]

- One-step subtyping (Page 12): [[./html/DecSyn.fp_red.html#Sub1][Sub1]]
- Untyped subtyping (Def. 3.2): [[./html/DecSyn.fp_red.html#Sub][Sub]]
- Untyped subtyping (w.r.t $\eta$-reduction): [[./html/DecSyn.fp_red.html#ESub][ESub]]

Note that [[./html/DecSyn.fp_red.html#ESub][ESub]] holds when two terms can be related by one-step
subtyping after $\eta$-reduction. It is not mentioned in the paper but
is convenient to have around in the mechanization for automation purposes.
**** Coquand's algorithm (Sec. 4.1)
Coquand's algorithm is one of the exceptions of the above naming
scheme, and the actual formal definition is slightly different from
the text presentation. Notably, the algorithmic equality for head
normal forms is split into two relations, one that handles the case
where both terms are neutral, and one that handles the cases where at
least one term is not neutral.


- Algorithmic equality ($a \leftrightarrow b$ in the text): [[./html/DecSyn.algorithmic.html#CoqEq_R][CoqEq_R]] ($a
  \Leftrightarrow b$ in the mechanization)
- Algorithmic equality for head normal forms ($f_0 \sim f_1$ in the
  text):
  + When both inputs are neutral: [[./html/DecSyn.algorithmic.html#CoqEq_Neu][CoqEq_Neu]] ($a \sim b$ in the mechanization)
  + Otherwise: [[./html/DecSyn.algorithmic.html#CoqEq][CoqEq]] ($a \leftrightarrow b$ in the mechanization)

The relations are all formulated on arbitrary terms.  The neutral and
normal form restrictions in $f_0 \sim f_1$ are proven a posteriori as
lemmas in the mechanization (e.g. [[./html/DecSyn.executable_correct.html#coqeq_no_hred][coqeq_no_hred]]).


Subtyping works similarly, though there is no need to split the
relation as the neutral case is handled by equalities.

- Algorithmic subtyping ($A \ll B$): [[./html/DecSyn.algorithmic.html#CoqLEq_R][CoqLEq_R]]
- Algorithmic subtyping for head normal forms ($f_0 \lesssim f_1$): [[./html/DecSyn.algorithmic.html#CoqLEq][CoqLEq]]

*** The untyped logical predicate (Sec 3.7)
As mentioned in the text, the definition of the logical predicate
cannot be written in Rocq directly as it consists of an inductive
definition nested in a fixpoint definition over universe levels.

The technique we adopt to encode the logical relation is described in
detail in the [[https://www.seas.upenn.edu/~sweirich/papers/liu-mltt-consistency.pdf][write-up]] by Liu and Weirich. To make the code more
readable, we specify a module type [[./html/DecSyn.logrel.html#LogRel][LogRel]] that includes the
introduction and induction principles that fully characterizes the
logical predicate. The module [[./html/DecSyn.logrel.html#LogRelImpl][LogRelImpl]] shows how the logical
predicate is actually defined through the inductive definition
[[./html/DecSyn.logrel.html#LogRelImpl.InterpExt][InterpExt]] and the fixpoint [[./html/DecSyn.logrel.html#LogRel.InterpUniv][InterpUniv]], the latter of which the logical
predicate satisfying the abstract properties we actually need.

By encapsulating the Rocq-specific workarounds behind the module
signature, the properties about the logical predicate (found in
[[./html/DecSyn.logrel.html#LogRelFactsImpl][LogRelFactsImpl]]) can be implemented purely in terms of the clean
interface specified in [[./html/DecSyn.logrel.html#LogRel][LogRel]].

- logical predicate ($\llbracket A \rrbracket \searrow S$):
  InterpUniv ([[./html/DecSyn.logrel.html#LogRel.InterpUniv][signature]], [[./html/DecSyn.logrel.html#LogRelImpl.InterpUniv][implementation]])
  + induction principle ([[./html/DecSyn.logrel.html#LogRel.InterpUniv_ind][signature]], [[./html/DecSyn.logrel.html#LogRelImpl.InterpUniv_ind][implementation]])
  + introduction rules (omitted, defined in the same module)

To avoid introducing propositional and functional extensionality
axioms, we add rule [[./html/DecSyn.logrel.html#LogRel.InterpUniv_Conv][InterpUniv_Conv]] to our mechanization
to ensure that the logical predicate operates on predicates that are
extensionally equivalent (denoted by $\doteq$ in the
mechanization). These artifacts introduced by avoiding the axioms are
noted in the development and can be safely ignored.

*** Executable conversion algorithm (Sec. 4)
The relational definition of algorithmic conversion is not immediately
executable. The decidability result (Theorem 4.1) is justified by
defining a total function that returns true precisely when two of its
input are convertible.

Here, we give links to the definition of the algorithm and the
Bove-Capretta domains to handle termination checking.

- Executable algorithmic
  - subtyping: [[./html/DecSyn.executable.html#check_sub_r][check_sub_r]]
  - equality: [[./html/DecSyn.executable.html#check_equal_r][check_equal_r]]
- Bove-Capretta domains for
  - subtyping: [[./html/DecSyn.common.html#salgo_dom_r][salgo_dom_r]]
  - equality: [[./html/DecSyn.common.html#algo_dom_r][algo_dom_r]]

The completeness and soundness of the computable functions with
respect to their relational counterparts are not explicitly included
in the paper, but they are linked in the mechanization by the
following lemmas.

- subtyping: [[./html/DecSyn.executable_correct.html#check_sub_sound][check_sub_sound]], [[./html/DecSyn.executable_correct.html#check_sub_complete][check_sub_complete]]
- equality: [[./html/DecSyn.executable_correct.html#check_eq_sound][check_eq_sound]], [[./html/DecSyn.executable_correct.html#check_eq_complete][check_eq_complete]]

The termination of algorithmic conversion is implied by the
above completeness and soundness results.

** Properties proven in the paper
The definition of the logical relation is split into =InterpExt= and
=InterpUniv= in [[file:theories/logrel.v][logrel.v]].

*** Section 2
- Lemma 2.1 (context regularity) :: [[file:./theories/structural.v][structural.v]], =wff_mutual=
- Lemma 2.2 (generation) :: [[file:./theories/structural.v][structural.v]], [[file:theories/admissible.v][admissible.v]], =*_Inv=
- Lemma 2.3 (subject reduction) :: [[file:theories/preservation.v][preservation.v]], =RRed_Eq=, =subject_reduction=
- Lemma 2.4 (regularity) :: [[file:./theories/structural.v][structural.v]], =regularity=
*** Section 3
- Lemma 3.1 :: [[file:theories/fp_red.v][fp_red.v]], =RRed.nf_imp=
- Lemma 3.2 :: [[file:theories/fp_red.v][fp_red.v]], =ERed.nf_preservation=
- Lemma 3.3 :: [[file:theories/fp_red.v][fp_red.v]], =LoReds.FromSN_mutual=
- Lemma 3.4 (no stuck terms) :: [[file:theories/fp_red.v][fp_red.v]], =SN_NoForbid.*_imp=
- Lemma 3.5 (sn antisubstitution) :: [[file:theories/fp_red.v][fp_red.v]], =sn_unmorphing=
- Lemma 3.6 (sn preservation) :: [[file:theories/fp_red.v][fp_red.v]],  =RERed.sn_preservation=,
  =epar_sn_preservation=, =red_sn_preservation=
- Lemma 3.7 (restrictive-$\eta$ and normal form) :: [[file:theories/fp_red.v][fp_red.v]], =R_elim_nf=
- Lemma 3.8 ($\eta$-decomposition) :: [[file:theories/fp_red.v][fp_red.v]], =η_split=
- Lemma 3.9 ($\eta$-postponement) :: [[file:theories/fp_red.v][fp_red.v]], =η_postponement=
- Corollary 3.1 (strengthened $\eta$-postponement) :: [[file:theories/fp_red.v][fp_red.v]], =η_postponement_star'=
- Corollary 3.2 ($\eta$-postponement for normal forms) :: [[file:theories/fp_red.v][fp_red.v]], =standardization=
- Lemma 3.10 (confluence for $\beta$) :: [[file:theories/fp_red.v][fp_red.v]], =red_confluence=
- Lemma 3.11 (confluence for $\eta$) :: [[file:theories/fp_red.v][fp_red.v]], =ered_confluence=
- Theorem 3.1 (confluence for $\beta\eta$ :: [[file:theories/fp_red.v][fp_red.v]], =rered_confluence=
- Lemma 3.12 (transitivity of joinability) :: [[file:theories/fp_red.v][fp_red.v]], =DJoin.transitive=
- Lemma 3.13 (injectivity of joinability) :: [[file:theories/fp_red.v][fp_red.v]],
  =DJoin.hne_app_inj=, =DJoin.hne_proj_inj=
- Lemma 3.14 (transitivity of one-step subtyping) :: [[file:theories/fp_red.v][fp_red.v]],
  =Sub1.transitive=
- Lemma 3.15 (commutativity of one-step subtyping) :: [[file:theories/fp_red.v][fp_red.v]], =Sub1.commutativity0=
- Lemma 3.16 (one-step subtyping preserves sn) :: [[file:theories/fp_red.v][fp_red.v]], =Sub1.sn_preservation=
- Corollary 3.3 (transitivity of untyped subtyping) :: [[file:theories/fp_red.v][fp_red.v]], =Sub.transitive=
- Lemma 3.17 (noconfusion for untyped subtyping) :: [[file:theories/fp_red.v][fp_red.v]], =Sub.*_noconf=
- Lemma 3.18 (untyped injectivity of type constructors) :: [[file:theories/fp_red.v][fp_red.v]], =Sub.*_inj=
- Lemma 3.19 (adequacy) :: [[file:theories/logrel.v][logrel.v]], =adequacy=
- Lemma 3.20 (backward closure) :: [[file:theories/logrel.v][logrel.v]], =InterpUniv_back_clos=
- Lemma 3.21 (logical predicate cases) :: [[file:theories/logrel.v][logrel.v]], =InterpUniv_case=
- Lemma 3.22 (logical predicate is preserved by subtyping) ::
  [[file:theories/logrel.v][logrel.v]], =InterpUniv_Sub0=
- Corollary 3.4 (logical predicate is functional)  :: [[file:theories/logrel.v][logrel.v]], =InterpUniv_Functional=
- Lemma 3.23 (logical predicate is cumulative) :: [[file:theories/logrel.v][logrel.v]], =InterpUniv_cumulative=
- Lemma 3.24 (semantic weakening) :: [[file:theories/logrel.v][logrel.v]], =weakening_Sem=
- Lemma 3.25 (semantic substitution) :: [[file:theories/logrel.v][logrel.v]], =morphing_SemWt=
- Lemma 3.26 (structural rules for semantic well-formedness) :: [[file:theories/logrel.v][logrel.v]], =SemWff=
- Theorem 3.2 (fundamental theorem) :: [[file:theories/soundness.v][soundness.v]], =fundamental_theorem=
- Corollary 3.5 (completeness of reduce-and-compare) :: Inlined into
  proof scripts
- Corollary 3.6 (completeness of reduce-and-compare) :: [[file:theories/soundness.v][soundness.v]], =synsub_to_usub=
*** Section 4
- Lemma 4.1 ($\Pi$-subtyping) :: [[file:theories/logrel.v][logrel.v]], =Sub_Bind_Inv{L,R}=
- Lemma 4.2 (univ-subtyping) :: [[file:theories/logrel.v][logrel.v]], =Sub_Univ_Inv{L,R}=
- Lemma 4.3 (soundness for algorithmic equality) :: [[file:theories/algorithmic.v][algorithmic.v]], =coqeq_sound_mutual=
- Lemma 4.4 (soundness for algorithmic subtyping) :: [[file:theories/algorithmic.v][algorithmic.v]], =coqleq_sound_mutual=
- Lemma 4.5 (metric implies domain) :: [[file:theories/algorithmic.v][algorithmic.v]], =sn_term_metric=
- Lemma 4.6 (termination of Coquand's algorithm) :: [[file:theories/executable.v][executable.v]], =check_sub=
- Lemma 4.7 (completeness of Coquand's algorithm) :: [[file:theories/algorithmic.v][algorithmic.v]], =coqeq_complete'=
- Lemma 4.8 (completeness of Coquand's algorithmic subtyping) ::
  [[file:theories/algorithmic.v][algorithmic.v]], =coqleq_complete'=
- Lemma 4.9 (completeness of Coquand's algorithmic subtyping) ::
  [[file:theories/algorithmic.v][algorithmic.v]], lemmas near the end of the file
- Theorem 4.1 :: by composing 4.9 and 4.6
*** Section 5
- Proposition 5.1 :: [[file:theories/cosn.v][cosn.v]]  =Safe_NoForbid=

** Validating axiom usage
We claim that our development is axiom-free. To validate that claim,
one can use the =Print Assumptions= command on the theorems and
confirm that no axioms are displayed.

An alternative method is to run =coqchk=, which can be done by running
=make validate=. However, =coqchk= doesn't work that well with module
types and will report axioms that we didn't actually use in the
development.
